apiVersion: batch/v1
kind: Job
metadata:
  name: train
spec:
  ttlSecondsAfterFinished: 172800
  backoffLimit: 0                     
  template:
    spec:
      runtimeClassName: nvidia
      containers:
      - name: train
        image: rbarile17/grainsack
        env:
          - name: PYSTOW_HOME
            value: /lustrehome/robertobarile
          - name: TORCHINDUCTOR_CACHE_DIR
            value: /tmp/torchinductor
          - name: TORCHDYNAMO_CACHE_DIR
            value: /tmp/torchdynamo
        command: ["python", "-u", "-m", "grainsack.operations", "train"]
        resources:
          requests:
            cpu: "8"
            memory: "64Gi"
            nvidia.com/gpu: 1
          limits:
            cpu: "8"
            memory: "64Gi"
            nvidia.com/gpu: 1
        volumeMounts:
        - name: lustre
          mountPath: /lustre
        - name: lustrehome
          mountPath: /lustrehome
      restartPolicy: Never
      volumes:
      - name: lustre
        hostPath:
          path: /lustre
          type: Directory
      - name: lustrehome
        hostPath:
          path: /lustrehome
          type: Directory
      nodeSelector:
        nvidia.com/gpu.product: NVIDIA-A100-PCIE-40GB
